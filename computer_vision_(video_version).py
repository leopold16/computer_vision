# -*- coding: utf-8 -*-
"""Computer Vision (Video Version).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JVF1ksjMA3gCdlHoMcuKENcwnqxG3LTJ
"""

pip install inference

pip install pafy

pip install youtube-dl

pip install supervision as sv

import cv2
import numpy as np
from inference import get_model
import supervision as sv
from google.colab.patches import cv2_imshow


# Load a pre-trained YOLOv8n model
model = get_model(model_id="yolov8n-640")

# Open a video file or capture device
video = cv2.VideoCapture('/content/Shopping, People, Commerce, Mall, Many, Crowd, Walking   Free Stock video footage   YouTube.mp4')

# Check if video opened successfully
if not video.isOpened():
    print("Error: Could not open video.")
    exit()

# Annotators for bounding boxes and labels
bounding_box_annotator = sv.BoundingBoxAnnotator()
label_annotator = sv.LabelAnnotator()

while True:
    ret, frame = video.read()
    if not ret:
        print("Failed to retrieve frame.")
        break

    # Run inference on the frame
    results = model.infer(frame)

    # Convert results for visualization
    detections = sv.Detections.from_inference(results[0].dict(by_alias=True, exclude_none=True))

    # Annotate the frame with inference results
    annotated_frame = bounding_box_annotator.annotate(scene=frame, detections=detections)
    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections)

    # Convert the annotated frame back to BGR for OpenCV display
    annotated_frame = cv2.cvtColor(np.array(annotated_frame), cv2.COLOR_RGB2BGR)

    # Display the frame
    cv2_imshow(annotated_frame)

    # Break the loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture object
video.release()
cv2.destroyAllWindows()